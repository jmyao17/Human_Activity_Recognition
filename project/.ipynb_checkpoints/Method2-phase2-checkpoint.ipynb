{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the project\n",
    "\n",
    "Details:\n",
    "Ultimately this is a time-series classification project where you are trying to classify the following classes (codified by numbers): \n",
    "\n",
    "    1: Working at Computer\n",
    "    2: Standing Up, Walking and Going Up/Downstairs\n",
    "    3: Standing\n",
    "    4: Walking\n",
    "    5: Going Up/Down Stairs\n",
    "    6: Walking and Talking with Someone\n",
    "    7: Talking while Standing\n",
    "\n",
    "Though a full analysis is not required, a discussion of how the windowing of the data will affect the analysis is expected. The ideal classification model will be able to use minimal quantities/time windows of the data to predict each class (i.e. not the entire time-series per user per class).\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "    --- The dataset collects data from a wearable accelerometer mounted on the chest\n",
    "    --- Sampling frequency of the accelerometer: 52 Hz\n",
    "    --- Accelerometer data are uncalibrated\n",
    "    --- Number of participants: 15\n",
    "    --- Number of activities: 7\n",
    "    --- Data format: CSV\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "    --- Data are separated by the participant\n",
    "    --- Each file contains the following information:\n",
    "    --- Sequential number, x acceleration, y acceleration, z acceleration, label\n",
    "    --- Labels are codified by numbers\n",
    "\n",
    "Context: Uncalibrated Accelerometer Data are collected from 15 participants performing 7 activities. The dataset provides challenges for identification and authentication of people using motion patterns.\n",
    "\n",
    "Please provide preferably a Jupyter Notebook, or otherwise an R Markdown file, with your analysis.\n",
    "\n",
    "Evaluation Criteria:\n",
    "The mini-project will be evaluated on the following criteria:\n",
    "\n",
    "    1) Code and visualization quality (especially in exploring the data)\n",
    "    2) Feature generation/model creation/analysis flow/methodology.\n",
    "    3) Validation method(s)/metrics/statistics/plots\n",
    "    4) Conclusions/recommendations - Are we data limited, noise limited, overfitting/underfitting? How would you improve the model? i.e. I don't particularly care if the model is optimally tuned so long as you know where it can be improved and how much a bump you might expect.\n",
    "\n",
    "Caveat for Using Open-source Libraries/Packages:\n",
    "You are welcome to use any open-source libraries/packages/resources but keep in mind that you will be quizzed on details of what is going on under-the-hood. In particular, I would very much prefer if you didn't just use pre-trained algorithms/models. This goes especially for pre-trained models. In other words, we are not looking for a black-box solution that gets us X% even if it's better than what you are getting from engineering your own features.\n",
    "\n",
    "Sklearn/XGBoost and similar generic stuff are fair game - but you will be asked about tuning, limitations and/or improvements in the next stage if you don't already discuss them in your notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Code **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    " \n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, LeakyReLU\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.models import Sequential    \n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras_metrics as km\n",
    "\n",
    "#minorLocator = AutoMinorLocator()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(features):\n",
    "    dfs = [] \n",
    "    for i in range(1,16):\n",
    "    \n",
    "        filename = 'Activity Recognition from Single Chest-Mounted Accelerometer/'+str(i)+'.csv'\n",
    "    \n",
    "        df_temp = pd.read_csv(filename)\n",
    "        df_temp.columns = [features]\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "        print(\"Time Duration for the {}-th participant is {} seconds\".format(i,np.ceil(df_temp.shape[0]/52)))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_figstyle(xmin,xmax,ymin,ymax,xlabel,ylabel,how):\n",
    "    \"\"\"\n",
    "        how --  True: label both sides of y;\n",
    "                False: only label the left side\n",
    "    \"\"\"\n",
    "    plt.xlabel(xlabel,fontsize=24)\n",
    "    plt.ylabel(ylabel, fontsize=24)\n",
    "    plt.ylim(ymin,ymax)\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.tick_params(which='major',direction='in',length=10,labelsize=20)\n",
    "    plt.tick_params(which='minor',direction='in',length=5,labelsize=20)\n",
    "    plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=how,\n",
    "                    bottom=True, top=False, left=True, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data4AllClass(df,features):\n",
    "\n",
    "    x1 = features[0]\n",
    "    ys = features[1:]\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for y in ys[:-1]: \n",
    "        plt.scatter(dfs[0][x1],dfs[0][y],c=dfs[0][ys[-1]],label=y)\n",
    "\n",
    "    set_figstyle(0,dfs[0].shape[0],1300,3000,'sequential_number (k)','acceleration',True)\n",
    "    plt.gca().set_xticklabels([int(x/1000) for x in plt.gca().get_xticks()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data4EachClass(df, features):\n",
    "    \n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    ===========\n",
    "    df: DataFrame for each participant\n",
    "    features: column name in the DataFrame\n",
    "    \n",
    "    Output:\n",
    "    =======\n",
    "    divide the data based on class and plot each figure for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    x1 = features[0]\n",
    "    ys = features[1:]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(14,12)) \n",
    "    plt.tight_layout()   \n",
    "    \n",
    "\n",
    "    for i in range(1,8):\n",
    "        class_label = i  \n",
    "        \n",
    "        df_class = df[df['label'].values == i]\n",
    "\n",
    "        if i>7:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        plt.subplot(3,3,i)\n",
    "\n",
    "        plt.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "\n",
    "        for y in ys[:-1]:\n",
    "            plt.scatter(df_class[x1].values,df_class[y].values,label=y)\n",
    "\n",
    "\n",
    "        plt.gca().set_xticklabels([int(x/1000) for x in plt.gca().get_xticks()]) \n",
    "        plt.title('class'+  str(class_label))\n",
    "        plt.xlabel('sequential_number (k)')\n",
    "        plt.ylabel('acceleration')\n",
    "        plt.legend()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 15 participants\n",
    "\n",
    "def get_segments4All(dfs, window_size, step_size): \n",
    "    \n",
    "    segments = []\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    df = pd.concat(dfs[p] for p in range(0,len(dfs)))\n",
    "    \n",
    "        # loop over class [1,2,..,7]\n",
    "         \n",
    "    \n",
    "    for class_label in range(1,8):\n",
    "        \n",
    "        print(\"Processing the data of class: {}\\n\".format(class_label))\n",
    "         \n",
    "        df_class = df[df['label'].values == class_label]\n",
    "        assert len(df_class) > window_size\n",
    "\n",
    "\n",
    "            # for each  given class, slide the window\n",
    "            #for i in range(0,len(df_class)- window_size, step_size): \n",
    "            \n",
    "        # progress bar\n",
    "        f = IntProgress(min=0, max=len(df_class)) # instantiate the bar\n",
    "        display(f) # display the bar \n",
    "    \n",
    "        for i in range(0,len(df_class) - window_size, step_size):\n",
    "            start = i\n",
    "            end   = i + window_size\n",
    "            xseg = df_class['x_acceleration'].values[start: end]\n",
    "            yseg = df_class['y_acceleration'].values[start: end]\n",
    "            zseg = df_class['z_acceleration'].values[start: end]\n",
    "            segments.append([xseg, yseg, zseg]) \n",
    "            labels.append(class_label)\n",
    "            \n",
    "            f.value += step_size # signal to increment the progress bar\n",
    "            #time.sleep(.1)\n",
    "\n",
    "            \n",
    "    return labels,segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dfs, window_size, step_size, num_feature):\n",
    "    \n",
    "    labels4all,segments4all = get_segments4All(dfs, window_size, step_size)\n",
    "    segments4all_array      = np.array(segments4all, dtype=np.float64).reshape(-1,num_feature, window_size)\n",
    "    \n",
    "    return labels4all, segments4all_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simple(num_feature,window_size):\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(64, (2,2), activation='relu', input_shape=(num_feature,window_size,1))) # 64 nodes, 3x3 filter matrix\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(36, (2,2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def model_CX(num_feature,window_size):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()  \n",
    "    model.add(Conv2D(18, (2, 12), padding='same', input_shape=(num_feature,window_size,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2D(36, (1, 12), strides=2, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2D(24, (1, 12), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    def recall(y_true, y_pred):\n",
    "        \n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall    = recall(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Duration for the 1-th participant is 3125.0 seconds\n",
      "Time Duration for the 2-th participant is 2654.0 seconds\n",
      "Time Duration for the 3-th participant is 1969.0 seconds\n",
      "Time Duration for the 4-th participant is 2350.0 seconds\n",
      "Time Duration for the 5-th participant is 3077.0 seconds\n",
      "Time Duration for the 6-th participant is 2710.0 seconds\n",
      "Time Duration for the 7-th participant is 3135.0 seconds\n",
      "Time Duration for the 8-th participant is 2654.0 seconds\n",
      "Time Duration for the 9-th participant is 3207.0 seconds\n",
      "Time Duration for the 10-th participant is 2439.0 seconds\n",
      "Time Duration for the 11-th participant is 2009.0 seconds\n",
      "Time Duration for the 12-th participant is 2206.0 seconds\n",
      "Time Duration for the 13-th participant is 1301.0 seconds\n",
      "Time Duration for the 14-th participant is 2233.0 seconds\n",
      "Time Duration for the 15-th participant is 1991.0 seconds\n"
     ]
    }
   ],
   "source": [
    "features = ['Sequential_number', 'x_acceleration', 'y_acceleration', 'z_acceleration', 'label']\n",
    "dfs = load_data(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize data\n",
    "\n",
    "\n",
    "\n",
    "Here we take the data of the **first participant*** as an example to visualize the data, trying to find some features that are relevant for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** plot the data for each class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = False\n",
    "if plot_data:\n",
    "    plot_data4AllClass(dfs[0],features)\n",
    "    plot_data4EachClass(dfs[0],features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation\n",
    "\n",
    "\n",
    "Here we use so-called ***Full-None-Overlaping-Window***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters for the window\n",
    "num_feature = 3\n",
    "window_size = 520   # 10 senconds\n",
    "step_size   = 520   # 10 seconds\n",
    "segments    = []\n",
    "label       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfab949e76a4dd7a585d8a7f41e2523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=608652)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0586c6c06945a6badab9f57cae6f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=47878)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 3\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328d9287641d467084ecfb4fa8156604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=216737)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9fde4c3497490386128b40cb918465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=357064)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 5\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13ada643e544a5dbae1a401f3009532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=51498)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 6\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a76dd4221684220a232b705c1b13e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=47770)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d259e5023fb458eb70b200e85892f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=593563)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, segments4all_array = preprocess_data(dfs, window_size, step_size, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of segments: 3695\n",
      "segements shape: (3695, 3, 520)\n",
      "labels for segments:[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "print (\"number of segments: \" + str(len(labels))) \n",
    "print (\"segements shape: \" + str(segments4all_array.shape)) \n",
    "print (\"labels for segments:\" + str(list(set(labels)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are **3695** segments/samples. Each segement contains **520** sequential numbers. At each sequential number, there are **3** features (x_acceration, y_acceration, z_acceration).\n",
    "\n",
    "- Each segement has one label with the value ranging from 1 to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transform the class label into one-hot code **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: (3695, 7)\n"
     ]
    }
   ],
   "source": [
    "labels_OneHot = pd.get_dummies(labels)\n",
    "print (\"labels shape: \" + str(labels_OneHot.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Normalization for each segment **\n",
    "\n",
    "No evident difference is found in the accuracy between the choices of StandardScaler() and RobustScaler().\n",
    "However, the RobustScaler() takes much longer time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segements (scaled) shape: (3695, 3, 520)\n"
     ]
    }
   ],
   "source": [
    "scaler_pipeline = Pipeline([\n",
    "                    ('std_scaler',StandardScaler())    # Standardize features by removing the mean and scaling to unit variance\n",
    "                    #('robust_scaler',RobustScaler())  # Scale features using statistics that are robust to outliers.\n",
    "                    ])\n",
    "\n",
    "segments_scaled=[]\n",
    "for m in range(0, segments4all_array.shape[0]):\n",
    "    segments_scaled.append(scaler_pipeline.fit_transform(segments4all_array[m]))\n",
    "    \n",
    "segments_array_scaled = np.array(segments_scaled) \n",
    "print (\"segements (scaled) shape: \" + str(segments_array_scaled.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split the data into train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(segments_array_scaled,\n",
    "                                                    labels_OneHot, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test  = np.expand_dims(X_test, axis=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training segments = 2956\n",
      "number of test segments = 739\n",
      "X_train shape: (2956, 3, 520, 1)\n",
      "Y_train shape: (2956, 7)\n",
      "X_test shape: (739, 3, 520, 1)\n",
      "Y_test shape: (739, 7)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training segments = \" + str(X_train.shape[0]))\n",
    "print (\"number of test segments = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "\n",
    "\n",
    "Here, we adopt convolution neural network (CNN) to train the data.\n",
    "\n",
    "- The pros of using the CNN here is this model has achived a great success in the computer vision. In this project, we divide the whole time-series data into lots of segments. Each segement has dimension (3, window_size), which can be regarded as an image. Therefore, it is natural to think of this model.\n",
    "\n",
    "- The cons of this model is that this model belongs to ***black box*** models, which is not easy to interpret. \n",
    "\n",
    "- Both accuracy and f1 measure are adopted as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Apply the model settings proposed by Chen and Xue**\n",
    "\n",
    "Y. Chen, Y. Xue, \"A Deep Learning Approach to Human Activity Recognition Based on Single Accelerometer\", in IEEE International Conference on Systems, Man, and Cybernetics, 2015, pp. 1488\n",
    "\n",
    "Note: the dataset here might be different from that used in the above paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_CX = model_CX(num_feature, window_size)\n",
    "# both accuracy and f1 measure are adopted as metrics\n",
    "cnn_model_CX.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2956 samples, validate on 739 samples\n",
      "Epoch 1/10\n",
      "2956/2956 [==============================] - 3s 1ms/step - loss: 1.8092 - acc: 0.2865 - f1: 0.0000e+00 - val_loss: 1.6333 - val_acc: 0.3342 - val_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2956/2956 [==============================] - 3s 944us/step - loss: 1.5810 - acc: 0.3738 - f1: 0.0000e+00 - val_loss: 1.5526 - val_acc: 0.3992 - val_f1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2956/2956 [==============================] - 3s 929us/step - loss: 1.5290 - acc: 0.3708 - f1: 0.0000e+00 - val_loss: 1.5196 - val_acc: 0.3424 - val_f1: 0.0081\n",
      "Epoch 4/10\n",
      "2956/2956 [==============================] - 3s 927us/step - loss: 1.4660 - acc: 0.3840 - f1: 0.0556 - val_loss: 1.4537 - val_acc: 0.4506 - val_f1: 0.1432\n",
      "Epoch 5/10\n",
      "2956/2956 [==============================] - 3s 937us/step - loss: 1.4044 - acc: 0.4371 - f1: 0.2115 - val_loss: 1.3929 - val_acc: 0.4736 - val_f1: 0.2378\n",
      "Epoch 6/10\n",
      "2956/2956 [==============================] - 3s 972us/step - loss: 1.3205 - acc: 0.5010 - f1: 0.2482 - val_loss: 1.3307 - val_acc: 0.5034 - val_f1: 0.2766\n",
      "Epoch 7/10\n",
      "2956/2956 [==============================] - 3s 984us/step - loss: 1.2600 - acc: 0.5169 - f1: 0.3486 - val_loss: 1.3038 - val_acc: 0.5359 - val_f1: 0.4045\n",
      "Epoch 8/10\n",
      "2956/2956 [==============================] - 3s 983us/step - loss: 1.2167 - acc: 0.5426 - f1: 0.3691 - val_loss: 1.2793 - val_acc: 0.5535 - val_f1: 0.3295\n",
      "Epoch 9/10\n",
      "2956/2956 [==============================] - 3s 976us/step - loss: 1.1848 - acc: 0.5653 - f1: 0.4080 - val_loss: 1.2651 - val_acc: 0.5575 - val_f1: 0.4000\n",
      "Epoch 10/10\n",
      "2956/2956 [==============================] - 3s 994us/step - loss: 1.1610 - acc: 0.5802 - f1: 0.3932 - val_loss: 1.2501 - val_acc: 0.5562 - val_f1: 0.4341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f47edd8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "cnn_model_CX.fit(X_train, y_train, batch_size=500, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739/739 [==============================] - 0s 410us/step\n",
      "Loss = 1.2501320830862641\n",
      "Test Accuracy = 0.5561569689171886\n",
      "F1 score = 0.4296363300173789\n"
     ]
    }
   ],
   "source": [
    "preds = cnn_model_CX.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))  \n",
    "print (\"Test Accuracy = \" + str(preds[1]))\n",
    "print (\"F1 score = \" + str(preds[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   0   0   4   0   0 114]\n",
      " [  5   0   0   3   0   0  11]\n",
      " [ 22   0   0  26   0   0  43]\n",
      " [  8   0   2 126   0   0  12]\n",
      " [  8   0   1  10   0   0   5]\n",
      " [  1   0   0   3   0   0  10]\n",
      " [ 25   0   1  14   0   0 178]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_model_CX.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) \n",
    "y_test_classes = np.argmax(np.array(y_test).reshape(y_test.shape[0],7), axis=1) \n",
    "cm = confusion_matrix(y_test_classes,y_pred_classes)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 3, 520, 18)        450       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 260, 18)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 3, 260, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 130, 36)        7812      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 65, 36)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2, 65, 36)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 65, 24)         10392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 32, 24)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 10759     \n",
      "=================================================================\n",
      "Total params: 29,413\n",
      "Trainable params: 29,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model_CX.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison, let's try a simple **two-layer CNN model**, followed by a full-connected layer with an activation function, ***softmax*** for multi-class classification. No pooling layer.\n",
    "\n",
    "Of course, one can make the model more complicate by changing the hyperparametrs: filter size, number of filters, number of hidden layers and introduce batch normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_simple = model_simple(num_feature, window_size)\n",
    "cnn_model_simple.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2956 samples, validate on 739 samples\n",
      "Epoch 1/10\n",
      "2956/2956 [==============================] - 7s 2ms/step - loss: 2.4697 - acc: 0.2818 - f1: 0.2089 - val_loss: 1.7345 - val_acc: 0.3667 - val_f1: 0.3090\n",
      "Epoch 2/10\n",
      "2956/2956 [==============================] - 6s 2ms/step - loss: 1.5719 - acc: 0.3901 - f1: 0.2646 - val_loss: 1.6070 - val_acc: 0.3654 - val_f1: 0.1350\n",
      "Epoch 3/10\n",
      "2956/2956 [==============================] - 6s 2ms/step - loss: 1.4508 - acc: 0.4283 - f1: 0.2275 - val_loss: 1.4744 - val_acc: 0.4168 - val_f1: 0.2049\n",
      "Epoch 4/10\n",
      "2956/2956 [==============================] - 7s 2ms/step - loss: 1.3043 - acc: 0.5041 - f1: 0.2951 - val_loss: 1.3244 - val_acc: 0.5183 - val_f1: 0.2939\n",
      "Epoch 5/10\n",
      "2956/2956 [==============================] - 7s 2ms/step - loss: 1.1762 - acc: 0.5518 - f1: 0.3797 - val_loss: 1.2679 - val_acc: 0.5372 - val_f1: 0.3395\n",
      "Epoch 6/10\n",
      "2956/2956 [==============================] - 8s 3ms/step - loss: 1.0980 - acc: 0.5707 - f1: 0.4331 - val_loss: 1.2512 - val_acc: 0.5237 - val_f1: 0.3253\n",
      "Epoch 7/10\n",
      "2956/2956 [==============================] - 7s 2ms/step - loss: 1.0448 - acc: 0.5880 - f1: 0.4124 - val_loss: 1.2861 - val_acc: 0.4696 - val_f1: 0.3324\n",
      "Epoch 8/10\n",
      "2956/2956 [==============================] - 6s 2ms/step - loss: 1.0041 - acc: 0.5995 - f1: 0.4591 - val_loss: 1.2782 - val_acc: 0.5183 - val_f1: 0.4231\n",
      "Epoch 9/10\n",
      "2956/2956 [==============================] - 7s 2ms/step - loss: 0.9618 - acc: 0.6012 - f1: 0.4931 - val_loss: 1.3129 - val_acc: 0.4899 - val_f1: 0.3568\n",
      "Epoch 10/10\n",
      "2956/2956 [==============================] - 7s 2ms/step - loss: 0.9372 - acc: 0.6289 - f1: 0.4817 - val_loss: 1.3016 - val_acc: 0.5223 - val_f1: 0.3872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13dcc6be0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "cnn_model_simple.fit(X_train, y_train, batch_size=500, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739/739 [==============================] - 0s 433us/step\n",
      "Loss = 1.3015789310567596\n",
      "Test Accuracy = 0.5223274695534507\n",
      "F1 score = 0.38492080032906123\n"
     ]
    }
   ],
   "source": [
    "preds = cnn_model_simple.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))  \n",
    "print (\"Test Accuracy = \" + str(preds[1]))\n",
    "print (\"F1 score = \" + str(preds[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140   0   0   2   1   0  82]\n",
      " [  8   0   0   1   0   0  10]\n",
      " [ 15   0   0  18   1   0  57]\n",
      " [  8   0   3  99   1   0  37]\n",
      " [  2   0   2   4   2   0  14]\n",
      " [  1   0   0   1   0   0  12]\n",
      " [ 67   0   1   5   0   0 145]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_model_simple.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) \n",
    "y_test_classes = np.argmax(np.array(y_test).reshape(y_test.shape[0],7), axis=1) \n",
    "cm = confusion_matrix(y_test_classes,y_pred_classes)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 2, 519, 64)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 519, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 518, 36)        9252      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 18648)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 130543    \n",
      "=================================================================\n",
      "Total params: 140,371\n",
      "Trainable params: 140,243\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above two convolutional neural networks provide similar accuracy and f1 score for the training, validation and test data.\n",
    "\n",
    "- In the cnn_model_CX, the use of max pooling reduces the number of parameters significantly, reducing the possibility of overfitting to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window size effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters for the segmentation \n",
    "num_feature = 3 \n",
    "step_size   = 260        # frequency is 52 Hz.  \n",
    "segments    = []\n",
    "label       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_pipeline = Pipeline([\n",
    "                    ('std_scaler',StandardScaler())\n",
    "                    ])\n",
    "    \n",
    "def HAR_API(dfs,window_size):\n",
    "    \n",
    "    # Sample generation process\n",
    "    labels, segments4all_array = preprocess_data(dfs, window_size, step_size, num_feature)\n",
    "    \n",
    "    # encoding the label into one-hot\n",
    "    labels_OneHot = pd.get_dummies(labels)\n",
    "    \n",
    "\n",
    "    # scaling the data\n",
    "    segments_scaled = []\n",
    "    for m in range(0, segments4all_array.shape[0]):\n",
    "        segments_scaled.append(scaler_pipeline.fit_transform(segments4all_array[m]))\n",
    "\n",
    "    segments_array_scaled = np.array(segments_scaled) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(segments_array_scaled,labels_OneHot, \n",
    "                                                        test_size=0.2, random_state=None)\n",
    "    \n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    X_test  = np.expand_dims(X_test, axis=3) \n",
    "    \n",
    "    \n",
    "    cnn_model = cnn_model_CX(num_feature, window_size) # input parameters determine input X dimension\n",
    "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #train the model\n",
    "    cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n",
    "    \n",
    "    y_pred = cnn_model.predict(X_test)\n",
    "    \n",
    "    preds = cnn_model.evaluate(X_test, y_test)\n",
    "    print (\"Loss = \" + str(preds[0]))  \n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    return preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Window Size: 260\n",
      "\n",
      "Processing the data of class: 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929ded29882b443191a0aaccc49db02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=608652)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec22cc9f93740a3922d8a6daba4497e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=47878)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 3\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6c301ab98e4ee3b9c7676dc2300780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=216737)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e94c5c773154ba3b46f71a1392a2cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=357064)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 5\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b2804a520e4b11af120a9b60086b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=51498)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 6\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39805d155836463e92c21d62be353ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=47770)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the data of class: 7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181ad249b43c477a96f9c2cc65a3bdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=593563)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-2462ee2c7211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Window Size: {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHAR_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-28e5fd071eb3>\u001b[0m in \u001b[0;36mHAR_API\u001b[0;34m(dfs, window_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model_CX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "\n",
    "test_accuracy =[]\n",
    "\n",
    "for window_size in range(260,2600,260):  # 2s - 20 s\n",
    "    \n",
    "    print(\" Window Size: {}\\n\".format(window_size))\n",
    "    \n",
    "    test_accuracy.append([window_size, HAR_API(dfs,window_size)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[520, 0.5182679297152972],\n",
       " [1040, 0.5284552845528455],\n",
       " [1560, 0.4993215739484396],\n",
       " [2080, 0.5619047612965512],\n",
       " [2600, 0.47411444190412516],\n",
       " [3120, 0.45081967164258485],\n",
       " [3640, 0.5485636110834156],\n",
       " [4160, 0.33013698654632045],\n",
       " [4680, 0.2815934065934066]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[520, 0.5182679297152972]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_df = pd.DataFrame(test_accuracy)\n",
    "test_accuracy_df.columns=['window_size', 'test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_size</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>520</td>\n",
       "      <td>0.518268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>0.528455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1560</td>\n",
       "      <td>0.499322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2080</td>\n",
       "      <td>0.561905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.474114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3120</td>\n",
       "      <td>0.450820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3640</td>\n",
       "      <td>0.548564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4160</td>\n",
       "      <td>0.330137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4680</td>\n",
       "      <td>0.281593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_size  test_accuracy\n",
       "0          520       0.518268\n",
       "1         1040       0.528455\n",
       "2         1560       0.499322\n",
       "3         2080       0.561905\n",
       "4         2600       0.474114\n",
       "5         3120       0.450820\n",
       "6         3640       0.548564\n",
       "7         4160       0.330137\n",
       "8         4680       0.281593"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13e283a58>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_accuracy_df['window_size'].values, test_accuracy_df['test_accuracy'].values, c='r',label='ConvNet (epoch=10)')\n",
    "set_figstyle(520,5200,0,1,'Window Size','Test Accuracy',True) \n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "** Overfitting problem**\n",
    "\n",
    "- With the increase of epoch, the accuracy is smoothly increasing, while that of the validation data is almost constant (around 0.5).\n",
    "\n",
    "- The accuracy of the test data is similar to that of the validation dataset. It implies that there is  **overfitting** in the CNN model.\n",
    "\n",
    "- The number of total parameters is 124,839 which is more than one order of magnitude larger than the sample size (number of segments). The obvervation of overfitting is within expectation.\n",
    "\n",
    "- To reduce the overfitting, one may need more segments/samples. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
